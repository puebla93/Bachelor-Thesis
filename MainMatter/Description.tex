%===================================================================================
% Chapter: Description
%===================================================================================
\chapter{Descripción del Sistema}\label{chapter:description}
%===================================================================================

En este capítulo se describen los algoritmos seleccionados en cada una de las etapas descritas en el primer capítulo y se exponen las características de la cámara utilizada. Se definen formalmente algunas de las reglas y/o definiciones del béisbol que fueron tomadas en cuenta en el desarrolo del sistema y se propone una ubicación para la cámara dadas las características expuestas de la misma.

\section{Definiciones del Béisbol}

En el béisbol existen un conjunto de reglas o definiciones extremadamente importantes como es el caso de \textit{Zona de Strike}, \textit{Strike}, \textit{Bola}, etc. Para el desarrollo de este sistema fue necesario el conocimiento previo de varias de estas definiciones, las cuales serán presentadas formalmente en esta sección. Todas estas definiciones fueron tomadas de \cite{MLB}.

\subsection{Zona de Strike Actual}

En el béisbol, la zona de strike es el volumen de espacio por el que debe pasar un lanzamiento para contar como strike. La zona de strike oficial es el área sobre el \textit{Home Plate} desde el punto medio entre los hombros de un bateador y la parte superior de los pantalones del uniforme, cuando el bateador está en su posición y preparado para golpear una bola lanzada, y un punto justo debajo de la rótula (ver Fig. \ref{fig:StrikeZone}).

En las ligas juveniles, la zona de strike puede ser diferente. A menudo, la parte superior de la zona de strike está en las axilas, para que sea un poco más grande y más fácil para los árbitros.

\begin{figure}[!h]
    \centering
    \includegraphics[width=12cm]{Graphics/StrikeZone.png}
    \caption{Zona de Strike.}
    \label{fig:StrikeZone}
\end{figure}

\subsection{Cronología de la Zona de Strike}

Las especificaciones verticales de la zona de strike se han alterado varias veces durante la historia del béisbol (ver Fig. \ref{fig:StrikeZoneTimeLine}), la versión actual fue implementada en el año 1996.

Desde 1950-62, la zona de strike fue desde las axilas hasta la parte superior de las rodillas.

De 1963 hasta 1968, la zona de strike fue desde la parte superior de los hombros del bateador hasta las rodillas.

Desde 1969 hasta 1987, la zona de strike fue desde las axilas hasta la parte superior de las rodillas. Esta zona de strike fue implementada junto con la disminución de la altura del montículo de 15 pulgadas a 10 pulgadas, en respuesta a una temporada de 1968, ahora conocida como el ``Año del lanzador'', en la que el dominio de los lanzadores alcanzó nuevas alturas.

En los años comprendidos entre 1988 y 1995, la zona de strike fue desde el punto medio entre los hombros y la parte superior de los pantalones del uniforme, hasta la parte superior de las rodillas.

La versión de la zona de strike utilizada desde 1963 hasta 1968 también se utilizó antes de 1950, y se remonta a fines del siglo XIX.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{Graphics/StrikeZoneTimeLine.jpg}
    \caption{Cronología de la Zona de Strike.}
    \label{fig:StrikeZoneTimeLine}
\end{figure}

\subsection{Zona de Strike Utilizada}

La zona de strike utilizada fue una zona fija, esta zona está diseñada para ciertos análisis que se realizan luego de un partido de béisbol donde la altura del bateador no se conoce. Como la zona de strike se rigue por la estatura del bateador en turno, se utiliza una altura fija para estos, la cual es de 6 \textit{pies}. En función de esta altura el área de la zona de strike es calculada (ver Fig. \ref{fig:UsedStrikeZone}).

\begin{figure}[!h]
    \centering
    \includegraphics[width=8cm]{Graphics/PG-Zone.png}
    \caption{Zona de Strike utilizada.}
    \label{fig:UsedStrikeZone}
\end{figure}

\subsection{Strike}

Para determinar si un lanzamiento es una bola o un strike, el árbitro usa una zona de strike. La pelota debe estar dentro de la zona de strike para ser llamada strike. Durante cada turno al bate en el béisbol, el bateador recibe hasta tres strikes para golpear la pelota. Un strike es cada vez que el bateador se balancea en un lanzamiento y falla o cualquier lanzamiento que se encuentre en la zona de strike, ya sea que el bateador se balancee o no. ¡Tres strike y el bateador está afuera!

\subsection{Bola}

Se anota como bola (B) aquel lanzamiento del pitcher hacia el home que se encuentre fuera de la zona de strike.

\section{Cámara}

Para capturar las imágenes fue utilizada una cámara \textit{PlayStation Eye} \cite{PlayStationEye} (ver Fig. \ref{fig:PlayStationEye}). Este dispositivo se lanzó en el año 2007 con un precio de 20\textit{usd} como parte del sistema \textit{PlayStation Move} \cite{PlayStationMove}, una tecnología que permite a los usuarios interactuar con los juegos a partir de la detección del movimiento de un control remoto y el reconocimiento de gestos. También cuenta con un arreglo de cuatro micrófonos que permite el reconocimiento de voz.

Para que la detección de los movimientos sea precisa, la cámara \textit{PlayStation Eye} es capaz de capturar imágenes a una velocidad de 60 cuadros por segundo (\textit{fps}) con una resolución de 640x480 pixeles y 120\textit{fps} a 320x240. La mayor velocidad de \textit{fps}, es de 187\textit{fps} a 320x240 o 640x480 a 75\textit{fps} y se puede seleccionar con aplicaciones específicas como \textit{Freetrack} y \textit{Linuxtrack}. 

La cámara cuenta con un lente zoom de enfoque fijo ajustable en dos posiciones. Seleccionado manualmente al girar el cuerpo del lente, \textit{PlayStation Eye} se puede configurar en un ángulo de visión de 56 grados (\textit{punto rojo}), para el encuadre de primer plano en aplicaciones de chat o un ángulo de visión de 75 grados (\textit{punto azul}) para el encuadre \textit{long-shot} en aplicaciones interactivas de juegos físicos.

La interfaz de conexión es USB 2.0, por tanto puede utilizarse sin problemas en una computadora personal. La resolución, el precio y la alta velocidad de captura son los factores principales que influyeron en la elección de esta cámara para este sistema.

\section{Posición y Configuración de la Cámara}

Los sistemas existentes en su gran mayoría utilizan cámaras estereoscópicas de muy alta calidad, con una gran resolución y una alta velocidad de captura. Estas características se deben tener muy en cuenta en el análisis, en qué parte del estadio de béisbol serán ubicadas y el posicionamiento que tendrán dichas cámaras. En el caso de este sistema en particular se hizo un amplio estudio de las características que posee el dispositivo \textit{PlayStation Eye} para lograr una posición y ubicación donde sean aprovechadas al máximo las ventajas brindadas por la cámara.

\subsection{Configuración}

El ángulo de visión seleccionado fue de 75 grados (\textit{punto azul}), puesto que nos proporciona una campo de visión más amplio del terreno en comparación con la otra posible configuración ofrecida por la cámara, la cual es de 56 grados, mucho menor que la seleccionada.

Puesto que los lanzamientos en el béisbol son bastante rápidos (la bola rápida (recta) promedio de un lanzador de Grandes Ligas alcanza una velocidad de \textit{91mph} \cite{PitcherSpeed}) y que mientras más veces el sistema obtenga la posición de la pelota en un lanzamiento mejor será la aproximación de la función que describe su trayectoria, es necesario que la cámara utilizada posea una alta velocidad de captura. Con el objetivo de un mejor funcionamiento la cámara utilizada por el sistema fue ajustada a una configuración de 187\textit{fps} a 320x240, puesto que el dispositivo \textit{PlayStation Eye} permite configurar la velocidad de captura y resolución como fue expuesto anteriormente. Aunque esta resolución es un poco pobre, la velocidad de captura es considerablemente alta y brinda la posibilidad de poder capturar la pelota varias veces en cada lanzamiento.

\subsection{Posición}\label{sec:Position}

La cámara fue posicionada a una altura de aproximadamente $2.25$ metros sobre el \textit{Home Plate}, lo que proporciona un campo de visión de aproximadamente $3.45$ metros de largo (ver Fig. \ref{fig:CameraPosition}).

\begin{figure}[!h]
	\centering
	\begin{subfigure}[b]{0.4\linewidth}
		\includegraphics[width=\linewidth]{Graphics/CameraPosition.png}
		\caption{}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\linewidth}
		\includegraphics[width=\linewidth]{Graphics/ColorImage.png}
		\caption{}
	\end{subfigure}
    \caption{Posicionamiento de la cámara : (a) Posición de la cámara, (b) Vista de la cámara.}
    \label{fig:CameraPosition}
\end{figure}

Dada una mayor altura de la cámara con respecto a \textit{Home Plate} el campo de visión obtenido es más amplio (ver Fig. \ref{fig:VisionAreaGraphic}):
$$d=2*tan(\alpha/2)*h$$
donde $h$ es la altura de la cámara con respecto a \textit{Home Plate} ($2.25$ metros en nuestro caso), $\alpha$ el ángulo de visión (75 grados) y $d$ es el largo del campo de visión ($3.45$ metros).

\begin{figure}[!h]
        \centering
        \includegraphics[width=10cm]{Graphics/VisionAreaGraphic.png}
        \caption{Relación largo del campo de visión y altura de la cámara.}
        \label{fig:VisionAreaGraphic}
\end{figure}

A una mayor altura la cámara contará con un campo de visón más amplio lo que supone una ventaja pero también tiene un inconveniente, al colocar la cámara a una gran altura necesitaríamos que la cámara posea una mayor resolución, puesto que a mayor altura más lejos se observarán los objetos que se muestran en la imagen. La resolución en la configuración utilizada es de 320x240 por lo que no sería factible alejarse mucho más de la zona por donde pasa la pelota, debido a que esta se observaría en la imagen demasiado pequeña.

Un dato que interesa conocer es en cuántos frames se podrá observar la pelota en un lanzamiento a velocidad promedio. Esto se debe a que necesitamos que este dato sea lo suficientemente grande para poder obtener una aproximación de la trayectoria de la pelota con el menor error posible. Para conocer este dato es necesario calcular el tiempo $t$ en que la pelota recorre los $3.45$ metros del campo de visión:
$$t = \frac{d}{v}, \quad t = \frac{2*tan(37.5^{\circ})*2.25m}{91mph}, \quad t = 84.9ms (milisegundos)$$
Calculado este tiempo sabemos entonces que la pelota a una velocidad de \textit{91mph} recorre los $3.45$ metros del campo de visión en $84.9ms$. Dada la velocidad de captura utilizada (\textit{187fps}) y $t$ obtenemos:
$$n=\frac{2*tan(37.5^{\circ})*2.25m}{91mph}*187fps, \quad n=15.87 frames$$
donde $n$ es el número de frames en que se podrá observar la pelota en un lanzamiento.

La gráfica que muestra la relación entre el número de frames donde se observa la pelota en un lanzamiento y la velocidad de captura se muestra en la figura \ref{fig:NumberOfFrames} y la gráfica \ref{fig:NumberOfMiles} muestra la relación entre el número de frames donde se observa la pelota en un lanzamiento y la velocidad del lanzamiento en millas por hora (\textit{mph}).

\begin{figure}[!h]
    \centering
    \includegraphics[width=10cm]{Graphics/NumberOfFrames.png}
    \caption{Relación número de frames donde se observa la pelota y velocidad de captura en fps.}
    \label{fig:NumberOfFrames}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=10cm]{Graphics/NumberOfMiles.png}
    \caption{Relación número de frames donde se observa la pelota y velocidad del lanzamiento en \textit{mph}.}
    \label{fig:NumberOfMiles}
\end{figure}

\section{Eliminación de ruido}

La cámara PlayStation Eye permite establecer manualmente la velocidad de captura. Mientras más imágenes se capturen en un segundo, menos tiempo tiene el sensor de la cámara para medir la iluminación de la escena, por tanto las imágenes son más oscuras (ver Fig. \ref{fig:ImageNoiseFPS}) y como se puede observar en la gráfica \ref{fig:NoiseSNR}, también aumenta el ruido \cite{DVD}.

\begin{figure}[!h]
	\centering
	\begin{subfigure}[b]{0.24\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/ImageNoise15FPS.png}
		\text{15 \textit{fps}}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/ImageNoise30FPS.png}
		\text{30 \textit{fps}}
	\end{subfigure}\\
	\begin{subfigure}[b]{0.24\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/ImageNoise60FPS.png}
		\text{60 \textit{fps}}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/ImageNoise90FPS.png}
		\text{90 \textit{fps}}
	\end{subfigure}
	\begin{subfigure}[b]{0.24\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/ImageNoise120FPS.png}
		\text{120 \textit{fps}}
	\end{subfigure}
	\caption{Imágenes de una misma escena tomadas a distintas velocidades de captura. A medida que aumentan los \textit{fps}, las imágenes son más oscuras \cite{DVD}.}
	\label{fig:ImageNoiseFPS}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=12cm]{Graphics/NoiseSNR.png}
	\caption{Ruido en las imágenes a distintas velocidades de captura. Valores pequeños de SNR significan más ruido en la imagen \cite{DVD}.}
	\label{fig:NoiseSNR}
\end{figure}

Como es importante que la eliminación de ruido en el sistema se realice en tiempo real, es necesario aplicar un filtro sencillo y efectivo, pero que a su vez preserve las características de la imagen como bordes y texturas, este es el caso del filtro de mediana (ver sección \ref{sec:NoiseFilters}). Este filtro no está exento de eliminar los detalles de la imagen, de hecho si la vecindad es muy grande las texturas pierden definición. Para evitar que se afecten en gran medida los detalles de la imagen, se aplicó el filtro varias veces con un tamaño de ventana pequeño.

\section{Detección de \textit{Home Plate}}

Para poder detectar correctamente un objeto en una imagen es necesario el conocimiento previo de las características que posee dicho objeto. Es por esta razón que se hizo un estudio detallado de todas las características geométricas que describen a un \textit{Home Plate} (ver Fig. \ref{fig:HomePlateDimentions}) para su posterior detección en la imagen. Estas características geométricas fueron la base en el proceso de detección de \textit{Home Plate}, en el cual se hallaron todos los contornos sobre la imagen (ver Fig. \ref{fig:ImagesContours}) para luego ir filtrándolos por las características geométricas que mejor lo describan.

\begin{figure}[!h]
    \centering
    \includegraphics[width=8cm]{Graphics/HomePlateDimentions.png}
    \caption{Dimensiones del \textit{Home Plate} de béisbol.}
    \label{fig:HomePlateDimentions}
\end{figure}

\subsection{Contornos}

Los contornos se pueden explicar simplemente como una curva que une todos los puntos continuos (a lo largo del límite), teniendo el mismo color o intensidad. Los contornos son una herramienta útil para el análisis de formas, la detección de objetos y su reconocimiento \cite{Contours}. Para una mayor precisión, los contornos se hallan sobre imágenes binarias, por lo que antes de buscar un contorno sobre una imagen se aplica un umbral sobre la misma.

El umbral utilizado sobre la imagen para hallar los contornos fue el umbral adaptativo \cite{AdaptiveThreshold}. La principal razón por la cual se utilizó este umbral es debido a que pueden haber condiciones donde la imagen tenga diferente iluminación en diferentes áreas \cite{AdaptiveThresholdOpenCV}. El algoritmo de umbral adaptativo calcula el umbral para una pequeña región de la imagen, por lo que obtenemos diferentes umbrales para diferentes regiones de la misma imagen y nos da mejores resultados para las imágenes con iluminación variable \cite{AdaptiveThresholdOpenCV}.

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/ColorImage.png}
		\caption{}
	\end{subfigure}
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/ImageThresh.png}
		\caption{}
	\end{subfigure}    
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/AllContours.png}
		\caption{}
	\end{subfigure}    
	\caption{Contornos en una imagen : (a) Imagen original, (b) Imagen binaria, (c) Contornos en la imagen.}
	\label{fig:ImagesContours}
\end{figure}    

\subsection{Filtros a los Contornos}

Luego de haber hallado todos los contornos en la imagen tenemos que encontrar el contorno del \textit{Home Plate}. Para esto se fueron filtrando los contornos utilizando diferentes criterios, dichos criterios mayormente formaban parte de las características geométricas que definen al \textit{Home Plate} (ver Fig. \ref{fig:FilteredContours}). \\

\textbf{Filtrado por área.}
El primer filtro utilizado fue el filtrado por área, donde se tienen dos umbrales uno máximo y otro mínimo. Estos umbrales son porcentuales con respecto a la imagen, lo que permite utilizar diferentes tipos de resolución sin afectar la correctitud del sistema. Un contorno de área $X$ pasa el filtro de área (posible \textit{Home Plate}) si:
$$cpa \leq max\_cpa \quad \text{y} \quad cpa \geq min\_cpa \quad \text{con} \quad cpa = 100 * X / IA$$
donde $IA$ el área de la imagen, $cpa$ es el porciento del área de la imagen que ocupa el contorno, $max\_cpa$ es el umbral máximo y $min\_cpa$ el umbral mínimo. Los umbrales seleccionados para el sistema fueron $max\_cpa = 10$ y $min\_cpa = 1$ debido al campo de visión de la cámara.\\

\textbf{Filtrado por número de lados.}
Una de las características geométricas que posee el \textit{Home Plate} es que es un polígono de 5 lados (pentágono). Esta característica es un buen filtro debido a que muchos contornos en la imagen aunque sean un polígono no serán un pentágono (no tendrán 5 lados).\\

\textbf{Refinado de bordes.}
Puesto que el contorno que describe al \textit{Home Plate} no tiene exactamente la forma óptima, es necesario refinar mejor sus lados para así obtener una mejor proporción entre estos. Esto se logra encontrando la ubicación precisa de las esquinas o puntos de montura radial subpíxel (ver Fig. \ref{fig:CornerSubPix}).

\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{Graphics/CornerSubPix.png}
	\caption{Método de búsqueda de esquinas sub-pixel.}
	\label{fig:CornerSubPix}
\end{figure}

Este método se basa en la observación de que cada vector desde el centro $q$ hasta un punto $p$ ubicado dentro de un vecindario de $q$ es ortogonal al gradiente de imagen en $p$, sujeto a la imagen y al ruido de medición \cite{CornerSubPixOpenCV}.\\

\textbf{Filtrado de relación entre los lados.}
Otro de los filtros utilizados es el filtro de relación entre los lados. Como se muestra en la figura \ref{fig:HomePlateDimentions} el \textit{Home Plate} tiene dos pares de lados iguales, lo que supone una característica bastante particular de este pentágono. Al igual que en el filtrado por área la relación entre los lados iguales es porcentual y se tiene un umbral de diferencia entre los lados, esto está dado debido a que los lados rara vez van a ser exactamente iguales. Un lado de longitud $d_1$ es igual a otro de longitud $d_2$ si:
$$psd \leq psr \quad \text{con} \quad psd = \frac{100 * \mid d_1 - d_2 \mid}{min(d_1, d_2)}$$
donde $psd$ es el porciento del valor absoluto de la diferencia entre $d_1$ y $d_2$ y el menor de los dos lados y $psr$ es el umbral de diferencia entre los dos lados. El umbral seleccionado para el sistema fue $psr = 20$ debido al campo de visión de la cámara.\\

\textbf{Filtrado por ángulos.}
El último filtro utilizado fue el filtrado por ángulos. Como se muestra en la figura \ref{fig:HomePlateDimentions} el HomePlate tiene tres ángulos de 90º y dos de 135º, otra característica bastante particular de este pentágono. Al igual que en dos de los filtros anteriores este también cuenta con un umbral. Otra característica geométrica es que la lista de los ángulos consecutivos es una rotación de la siguiente [90º, 90º, 135º, 90º, 135º]. Un contorno pasa el filtro de ángulos (posible \textit{Home Plate}) si los 5 ángulos ordenados de forma consecutiva siguen el patrón anteriormente expuesto (o cualquiera de sus rotaciones) y:
\begin{equation*}
	\begin{split}
		\begin{split}
			& \mid \alpha_1 - 90^{\circ} \mid \\
			& \mid \alpha_2 - 90^{\circ} \mid \\
			& \mid \alpha_3 - 90^{\circ} \mid \\
			& \mid \beta_1 - 135^{\circ} \mid \\
			& \mid \beta_2 - 135^{\circ} \mid
		\end{split}
		& \quad \leq \quad umbral
	\end{split}
\end{equation*}
donde $\alpha_1$, $\alpha_2$, $\alpha_3$ son los tres ángulos menores y $\beta_1$, $\beta_2$ son los dos mayores. El umbral seleccionado para el sistema fue $umbral = 5$.

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/AllContours.png}
		\caption{}
	\end{subfigure}
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/FiltersContoursByArea.png}
		\caption{}
	\end{subfigure}
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/FiltersContoursBySidesNumber.png}
		\caption{}
	\end{subfigure}
	\caption{Filtros a contornos : (a) Todos los contornos, (b) Contornos filtrados por área, (c) Contornos filtrados por número de lados.}
	\label{fig:FilteredContours}
\end{figure}

\subsection{Rectificación de \textit{Home Plate}}

La detección de \textit{Home Plate} se realiza entre lanzamiento y lanzamiento, puesto que es más lenta que la velocidad de captura de la cámara. Esto está dado por el trabajo de filtrado que se realiza sobre los contornos en la imagen. Luego de que sean hayados en diferentes frames un conjunto de \textit{Home Plates}, los valores que definen su posición son promediados, esto permite obtener una mejor aproximación de la posición real que este ocupa en la imagen.

Para poder desempeñar un trabajo más comodo en las etapas posteriores a esta, la vista en la imagen es transformada a una vista \textit{top-down} o \textit{birds-eye} (ver Fig. \ref{fig:TopDownView}). El acto de transformar la imagen permite modificar el tamaño de la imagen resultante (1024x768) a una dimensión mayor que la original (320x240), sin perder el aspecto que poseen los objetos en esta imagen. La etapa de detección de la pelota se realiza sobre esta nueva imagen transformada.

\begin{figure}[!h]
	\centering
	\begin{subfigure}[b]{0.35\linewidth}
		\includegraphics[width=\linewidth]{Graphics/ColorImage.png}
		\caption{}
	\end{subfigure}
	\begin{subfigure}[b]{0.35\linewidth}
		\includegraphics[width=\linewidth]{Graphics/TopDownViewWraped.png}
		\caption{}
	\end{subfigure}
	\caption{Transformación de la vista en la imagen : (a) Imagen Original, (b) Vista \textit{top-down}.}
	\label{fig:TopDownView}
\end{figure}

\section{Detección de la Pelota}

Una de las restricciones que impone el sistema es el hecho de que la cámara tiene una posición fija sobre el \textit{Home Plate}. Esto nos brinda la ventaja de que el área observada por la cámara es estática, lo que implica que no cambia entre lanzamiento y lanzamiento. Esta restricción del sistema y el hecho de que en un lanzamiento la pelota está en constante movimiento son las principales bases del módulo de detección de la pelota. Un excelente algoritmo para identificar un objeto en movimiento dada una secuencia de frames y la cámara en una posición estática es Background Subtraction (ver sección \ref{sec:BS}).

\subsection{Background Subtraction}

Debido a que el uso del sistema propuesto será en exteriores, el modelo de BS seleccionado fue Mezcla Gaussiana (GMM). Este modelo brinda grandes ventajas en un ambiente de exteriores (al aire libre), puesto que funciona mejor cuando el fondo es inestable o cuando el nivel de ruido es significativamente grande \cite{YannickPierreMarcBrunoHeleneChristophe}. Esta ventaja está dada debido a que el modelado de fondo se realiza como un fenómeno estadístico (aleatorio) en lugar de una constante. Los ruidos en las imágenes de exteriores están dado mayormente por fluctuación de la cámara y cambio de luz, ruidos en los que el modelo GMM se adapta muy bien \cite{GMM}.

Luego de aplicar GMM sobre la imagen al resultado obtenido se le aplica una transformación morfológica. Las transformaciones morfológicas son algunas operaciones simples basadas en la forma de la imagen, las cuales se realizan en imágenes binarias. Estas operaciones necesitan dos entradas, una es la imagen original, la segunda se llama elemento estructurador o \textit{kernel}, el cual decide la naturaleza de la operación. Dos operadores morfológicos básicos son erosión y dilatación, también existen sus variantes como apertura, cierre, gradiente, etc (ver Fig: \ref{fig:MorphOp}). también entran en juego \cite{MorphologicalTransformationsOpenCV}. La operación morfológica utilizada por el sistema es apertura, nombre que se le da a la operación de erosión seguida de dilatación. La forma del kernel utilizada es un círculo debido a que se ajusta mejor a la forma de la pelota.

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/MorphOp_OriginalImage.png}
		\caption{}
	\end{subfigure}
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/MorphOp_Erotion.jpg}
		\caption{}
	\end{subfigure}
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/MorphOp_Dilation.jpg}
		\caption{}
	\end{subfigure}
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/MorphOp_Opening.jpg}
		\caption{}
	\end{subfigure}
	\begin{subfigure}[b]{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Graphics/MorphOp_Closing.jpg}
		\caption{}
	\end{subfigure}
	\caption{Operaciones morfológicas : (a) Imagen original, (b) Erosión, (c) Dilatación, (d) Apertura, (e) Cierre.}
	\label{fig:MorphOp}
\end{figure}

\subsection{Filtrado a la Pelota}

Como el algoritmo de BS se considera un problema de clasificación, es posible que se detecte un objeto como primer plano y que este no lo sea (falso positivo FP). Es por esto que luego de etiquetados todos los objetos que forman parte del primer plano, se filtran por su radio. Cada objeto es aproximado por un círculo, lo que nos proporciona el radio de dicho objeto y luego se aplica el filtro. El filtro de radio cuenta con dos umbrales uno máximo y otro mínimo, los cuales son porcentuales con respecto a la imagen. Un objeto de radio $r$ pasa el filtro de radio (posible pelota) si:
$$rp \leq max\_rp \quad \text{y} \quad rp \geq min\_rp \quad \text{con} \quad rp = 100*r/IA$$
donde $IA$ el área de la imagen, $rp$ es el porciento del área de la imagen que ocupa el radio, $max\_rp$ es el umbral máximo y $min\_rp$ el umbral mínimo. Los umbrales seleccionados para el sistema fueron $max\_rp = 0.01$ y $min\_rp = 0.002$ debido al campo de visión de la cámara. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=7cm]{Graphics/BallDimentions.jpg}
    \caption{Dimensiones de la pelota de béisbol.}
    \label{fig:BallDimentions}
\end{figure}

\section{Aproximación de la trayectoria de la pelota}

Luego de obtener el conjunto de puntos en la imagen donde se encontró la pelota, es necesario hallar una función que los aproxime. En este conjunto de puntos obtenidos puede que todavía queden algunos que fueron identificados falsamente como una pelota, a los puntos con estas características se les denomina \textit{outliers}. Debido a esto es conveniente utilizar un método que no tenga en cuenta la presencia de estos \textit{outliers}, de lo contrario puede que no se obtenga una buena aproximación de la trayectoria de la pelota. El método utilizado por el sistema para aproximar eficientemente este conjunto de puntos es \textit{RANSAC} (ver sección \ref{sec:RANSAC}). El modelo utilizado por \textit{RANSAC} para aproximar la trayectoria de la pelota es la función cuadrática:
$$f(x) = ax^2+bx+c$$

Las funciones cuadráticas han demostrado ser buenas aproximaciones de los conjuntos de puntos que se encuentran a una distancia relativa pequeña, como es el caso de este sistema en donde el campo de visón es de $3.45$ metros. Luego de aplicar \textit{RANSAC} a este conjunto de puntos obtenemos la función que describe la trayectoria de la pelota (ver Fig: \ref{fig:BallTrajectory}) en el eje horizontal de la zona de strike.

\begin{figure}[!h]
    \centering
    \includegraphics[width=10cm]{Graphics/BallTrajectory.png}
    \caption{Aproximación de la trayectoria de la pelota.}
    \label{fig:BallTrajectory}
\end{figure}

Con este resultado se responde a la pregunta de si la pelota pasó por encima de \textit{Home Plate} o no. Otro dato que interesa conocer para poder caracterizar el lanzamiento es a que altura pasó la pelota por encima de \textit{Home Plate}. Para conocer la altura de la pelota se utilizó su radio en pixeles, puesto que a mayor radio más cerca esta la pelota de la cámara y por consecuente a mayor altura con respecto a \textit{Home Plate}. El radio de la pelota también es aproximado con \textit{RANSAC}, utilizado la misma función cuadrática anteriormente expuesta como modelo (ver Fig: \ref{fig:BallRadius}).

\begin{figure}[!h]
    \centering
    \includegraphics[width=10cm]{Graphics/BallRadius.png}
    \caption{Aproximación del radio de la pelota.}
    \label{fig:BallRadius}
\end{figure}

Para conocer la altura de la pelota con respecto a \textit{Home Plate} se calcula previamente el tamaño en pixeles del diámetro de la pelota en el piso (a la altura de \textit{Home Plate}). Este cálculo se lleva a cabo mediante la siguiente fórmula:

$$\frac{ball\_diameter_{pixels}}{home\_large_{pixels}} = \frac{ball\_diameter_{inches}}{home\_large_{inches}}$$\\
donde el largo de \textit{Home Plate} en pulgadas es conocido (ver Fig: \ref{fig:HomePlateDimentions}) y el diámetro de la pelota en pulgadas es conocido (ver Fig: \ref{fig:BallDimentions}). Sustituyendo los valores conocidos y despejando $ball\_diameter_{pixels}$ nos queda:
$$ball\_diameter_{pixels} = \frac{2.86}{17}*home\_large_{pixels}$$
donde $home\_large_{pixels}$ es el largo de \textit{Home Plate} en pixeles, el cual se conoce a partir del \textit{Home Plate} detectado previamente. Con este resultado obtenemos el tamaño en pixeles del diámetro de la pelota en el piso, lo que nos permite calcular a que altura se encuentra la pelota del piso mediante la siguiente fórmula:
$$ball\_high_{cm} = camera\_high_{cm} - (camera\_high_{cm}*\frac{ball\_diameter_{pixels}}{ball\_pixels})$$
donde $camera\_high_{cm}$ es la altura a la que se encuentra la cámara del piso y $ball\_pixels$ es el diámetro de la pelota cuando pasa justo por encima de \textit{HomePlate}. Dado que la altura a la que se encuentra la cámara del piso en el sistema es $225\text{ }cm$, la fórmula queda de la siguiente forma:
$$ball\_high_{cm} = 255 - (255*\frac{ball\_diameter_{pixels}}{ball\_pixels})$$

Luego de realizados todos estos cálculos se tiene el punto por donde paso la pelota en la zona de strike, lo que nos permite caracterizar el lanzamiento en \textit{strike} o \textit{bola} (ver Fig: \ref{fig:PitchCall}).

\begin{figure}[!h]
	\centering
	\begin{subfigure}[b]{0.45\linewidth}
		\includegraphics[width=\linewidth]{Graphics/Strike.jpg}
		\caption{}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth}
		\includegraphics[width=\linewidth]{Graphics/Ball.jpg}
		\caption{}
	\end{subfigure}
	\caption{Caracterización del lanzamiento : (a) Strike, (b) Bola.}
	\label{fig:PitchCall}
\end{figure}

\section{Herramientas}

Para la calibración de la cámara y el procesamiento, análisis y manejo en general de las imágenes se utilizó la plataforma \textit{OpenCV} con el lenguaje \textit{Python}. Esta es una biblioteca de algoritmos de visión por computadoras que está enfocada principalmente en el procesamiento de imágenes en tiempo real. Para el trabajo con matrices y vectores fue utilizada la biblioteca \textit{NumPy}. Esta es una biblioteca de funciones matemáticas de alto nivel escrita en \textit{Python} y \textit{C}. Además de sus usos científicos, \textit{NumPy} también se puede usar como un contenedor multidimensional eficiente de datos genéricos, en el cual se pueden definir tipos de datos arbitrarios. Esto permite a la biblioteca integrarse de manera rápida y sin problemas con una amplia variedad de bases de datos.

A pesar de que el trabajo se desarrolló en el sistema operativo \textit{Ubuntu 16.04}, la herramienta \textit{OpenCV} y la biblioteca \textit{NumPy} son multiplataforma, lo que permite portar el software principal con relativa facilidad a otros sistemas operativos.
